// The generated lexer module will start with this code
{
module FM4FUNLexer
open FSharp.Text.Lexing
open System.Globalization
open System
// open the module that defines the tokens
open FM4FUNParser
}

// Macros for regular expressions:
let keywords    = ("if"|"fi"|"do"|"od"|"skip"|"true"|"false")
let digit       = ['0'-'9']
let var         = ['a'-'z''A'-'Z'](['a'-'z']|['A'-'Z']|digit|'_')*
let num         = digit+
// We choose to split up newlines and whitespace, so we can
// tell the LexBuffer that a new line has begun. This allows
// us to show positions of errors in multi-line input.
let newline     = "\n\r" | '\n' | '\r'
let whitespace  = ['\u00A0' ' ' '\r' '\t'] 
// OBS: We could not make \u00A0 work with "regular" whitespaces, so 
// we added ' ' to the regular expression. 

// Rules for each token in our language:
rule tokenize = parse

// Checking first for keywords with a mandatory whitespace
| "if" newline   { lexbuf.EndPos <- lexbuf.EndPos.NextLine; IF }
| newline "fi"   { lexbuf.EndPos <- lexbuf.EndPos.NextLine; FI }
| "do" newline   { lexbuf.EndPos <- lexbuf.EndPos.NextLine; DO }
| newline "od"   { lexbuf.EndPos <- lexbuf.EndPos.NextLine; OD }

// If the whitespaces are not newlines
| "if" whitespace   { IF }
| whitespace "fi"   { FI }
| "do" whitespace   { DO }
| whitespace "od"   { OD }

// Then ignoring the rest of whitespace
| newline           { lexbuf.EndPos <- lexbuf.EndPos.NextLine; tokenize lexbuf; }
| whitespace        { tokenize lexbuf }
| ":="              { ASSIGN }
| "skip"            { SKIP }
| ';'               { SEP }
| "->"              { THEN }
| "[]"              { CONS }
| '['               { LBRA }
| ']'               { RBRA }
| '+'               { PLUS }
| '-'               { MINUS }
| '*'               { MULT }
| '/'               { DIV }
| '^'               { POW }
| '('               { LPAR }
| ')'               { RPAR }
| "true"            { TRUE }
| "false"           { FALSE }
| "&&"              { SAND }
| "||"              { SOR }
| '&'               { AND }
| '|'               { OR }
| "!="              { NEQ }
| ">="              { GEQ }
| "<="              { LEQ }
| '='               { EQ }
| '>'               { GT }
| '<'               { LT }
| '!'               { NOT }

// Throws an error saying that if,fi,do,od is not allowed here.
| "if"              { INVALID }
| "fi"              { INVALID }
| "do"              { INVALID }
| "od"              { INVALID }

// Lastly it checks for variable names. Since the rules are applied top-down
| var               { VAR(LexBuffer<_>.LexemeString lexbuf)}
| num               { NUM((int) (LexBuffer<_>.LexemeString lexbuf)) }
| eof               { EOF }
| _                 { INVALID }






